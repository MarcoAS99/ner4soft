{"id": 1, "title": "Flow-Guided-Feature-Aggregation-README.md", "text": "1. MXNet from [the offical repository](https://github.com/apache/incubator-mxnet). We tested our code on [MXNet@(v0.10.0)](https://github.com/apache/incubator-mxnet/tree/v0.10.0). Due to the rapid development of MXNet, it is recommended to checkout this version if you encounter any issues. We may maintain this repository periodically if MXNet adds important feature in future release.\n\n2. Python packages might missing: cython, opencv-python >= 3.2.0, easydict. If `pip` is set up on your system, those packages should be able to be fetched and installed by running\n\t```\n\tpip install Cython\n\tpip install opencv-python==3.2.0.6\n\tpip install easydict==1.6\n\t```\n3. For Windows users, Visual Studio 2015 is needed to compile cython module.\n\n\n"}
{"id": 2, "title": "Flow-Guided-Feature-Aggregation-README.md", "text": "Any NVIDIA GPUs with at least 8GB memory should be OK.\n\n"}
{"id": 3, "title": "LapSRN-README.md", "text": "- MATLAB (we test with MATLAB R2017a on Ubuntu 16.04 and Windows 7)\n- Cuda & Cudnn (we test with Cuda 8.0 and Cudnn 5.1)\n\n"}
{"id": 4, "title": "DCPDN-README.md", "text": "1. Linux\n2. Python 2 or 3\n3. CPU or NVIDIA GPU + CUDA CuDNN (CUDA 8.0)\n \n"}
{"id": 5, "title": "gempy-README.md", "text": "*GemPy* requires Python 3 and makes use of numerous open-source libraries:\n\n* pandas>=0.21.0\n* cython\n* Theano\n* matplotlib\n* numpy\n* pytest\n* nbsphinx\n* seaborn\n* networkx\n* ipywidgets\n\nOptional:\n\n* git+git://github.com/Leguark/scikit-image@master\n* steno3d\n* vtk\n* gdal\n* qgrid\n* pymc\n* pymc3\n\n* `vtk>=7` for interactive 3-D visualization \n* `pymc` or `pymc3`\n* `steno3d` \n\nOverall we recommend the use of a dedicated Python distribution, such as \n[Anaconda](https://www.continuum.io/what-is-anaconda), for hassle-free package installation. \nWe are currently working on providing GemPy also via Anaconda Cloud, for easier installation of\nits dependencies.\n\n"}
{"id": 6, "title": "DeepMVS-README.md", "text": "- **python 2.7**\n- **numpy 1.13.1**\n- **pytorch 0.3.0** and **torchvision**: Follow the instructions from [their website](http://pytorch.org/).\n- **opencv 3.1.0**: Run ``conda install -c menpo opencv`` or ``pip install opencv-python``.\n- **imageio 2.2.0** (with freeimage plugin): Run ``conda install -c conda-forge imageio`` or ``pip install imageio``. To install freeimage plugin, run the following Python script once:\n    ```python \n    import imageio\n    imageio.plugins.freeimage.download()\n    ```\n- **h5py 2.7.0**: Run ``conda install h5py`` or ``pip install h5py``.\n- **lz4 0.23.1**: Run ``pip install lz4``.\n- **cuda 8.0.61** and **16GB GPU RAM** (required for gpu support): The training codes use up to 14GB of the GPU RAM with the default configuration. We train our model with an NVIDIA Tesla P100 GPU. To reduce GPU RAM usage, feel free to try smaller ``--patch_width``, ``--patch_height``, ``--num_depths``, and ``--max_num_neighbors``. However, the resulting model may not show the efficacy as appeared in our paper.\n\n"}
{"id": 7, "title": "DeepMVS-README.md", "text": "- **python 2.7**\n- **numpy 1.13.1**\n- **pytorch 0.3.0** and **torchvision**: Follow the instructions from [their website](http://pytorch.org/).\n- **opencv 3.1.0**: Run ``conda install -c menpo opencv`` or ``pip install opencv-python``.\n- **imageio 2.2.0**: Run ``conda install -c conda-forge imageio`` or ``pip install imageio``.\n- **pyquaternion 0.9.0**: Run ``pip install pyquaternion``.\n- **pydensecrf**: Run ``pip install pydensecrf``.\n- **cuda 8.0.61** and **6GB GPU RAM** (required for gpu support): The testing codes use up to 4GB of the GPU RAM with the default configuration. \n- **COLMAP 3.2**: Follow the instructions from [their website](https://colmap.github.io/). \n \n"}
{"id": 8, "title": "Shapely-README.md", "text": "Shapely 1.6 requires\n\n* Python 2.7, >=3.4\n* GEOS >=3.3 \n\n"}
{"id": 9, "title": "nextflow-io-nextflow-README.md", "text": "* Compiler Java 8\n* Runtime Java 8 or later\n\n"}
{"id": 10, "title": "CU-Net-README.md", "text": "This package has the following requirements:\n\n* `Python 2.7`\n* `Pytorch v0.4.0` or `Pytorch v0.1.12`\n\nNote that the script name with string `prev-version` requires `Pytorch v0.1.12`.\n\n"}
{"id": 11, "title": "geonotebook-README.md", "text": "For default tile serving\n  + GDAL >= 2.1.0\n  + mapnik >= 3.1.0\n  + python-mapnik >= 0.1\n\n"}
{"id": 12, "title": "two-stream-dyntex-synth-README.md", "text": "- Tensorflow 1.3 (or latest, although not tested)\n- Preferably a Titan X for synthesizing 12 frames\n- Appearance-stream [tfmodel](https://drive.google.com/open?id=19KkFi92oWLzuOWnGo6Zsqe-2CCXFAoXZ)\n- Dynamics-stream [tfmodel](https://drive.google.com/open?id=1DHnzoNO-iTgMUTbUOLrigEmpPHmn_mT1)\n- [Dynamic textures](https://drive.google.com/open?id=0B5T9jWfa9iDySWJHZnpNZ2dHWUk)\n- [Static textures](https://drive.google.com/open?id=11yMiPXiuYvLCyoLfQf_dEG6kuav8h6_3) (for dynamics style transfer)\n\n"}
{"id": 13, "title": "PRM-README.md", "text": "* System (tested on Ubuntu 14.04LTS and Win10)\n* NVIDIA GPU + CUDA CuDNN (CPU mode is also supported but significantly slower)\n* [Python>=3.5](https://www.python.org)\n* [PyTorch>=0.4](https://pytorch.org)\n* [Jupyter Notebook](https://jupyter.org/install.html) and [ipywidgets](https://github.com/jupyter-widgets/ipywidgets) (required by the demo):\n\n    ```bash\n    #: enable the widgetsnbextension before you start the notebook server\n    jupyter nbextension enable --py --sys-prefix widgetsnbextension\n    ```\n\n"}
{"id": 14, "title": "facebookresearch-ResNeXt-README.md", "text": "See the fb.resnet.torch [installation instructions](https://github.com/facebook/fb.resnet.torch/blob/master/INSTALL.md) for a step-by-step guide.\n- Install [Torch](http://torch.ch/docs/getting-started.html) on a machine with CUDA GPU\n- Install [cuDNN v4 or v5](https://developer.nvidia.com/cudnn) and the Torch [cuDNN bindings](https://github.com/soumith/cudnn.torch/tree/R4)\n- Download the [ImageNet](http://image-net.org/download-images) dataset and [move validation images](https://github.com/facebook/fb.resnet.torch/blob/master/INSTALL.md#download-the-imagenet-dataset) to labeled subfolders\n\n"}
{"id": 15, "title": "vid2vid-README.md", "text": "- Linux or macOS\n- Python 3\n- NVIDIA GPU + CUDA cuDNN\n- PyTorch 0.4\n\n\n"}
{"id": 16, "title": "map-vectorizer-README.md", "text": "A few things to be installed in your system in order to work properly. So far it has been **tested on Mac OS X Lion** so these instructions apply to that configuration only. I am sure you will be able to adapt it to your current configuration.\n\n* [Python] with [OpenCV] and [PIL] \n    * If you use [PIP](https://pypi.python.org/pypi) (recommended) you will get the necessary Python packages with: `pip install -r requirements.txt`\n* [R] - Make sure it is in your PATH (so you can run it via command-line by typing `R`).\n* You'll need the following R packages. On OS X simply navigate to `Packages & Data`, choose your CRAN mirror region, then search for and install:\n    * `alphahull` (you will need `tripack`, `sgeostat`, `splancs` as dependencies)\n    * `igraph`\n    * `shapefiles`\n    * `rgdal` (download the [binary for your OS](http://cran.r-project.org/web/packages/rgdal/index.html) then run `R CMD INSTALL --configure-args=\"\" path/to/rgdal.tar.gz`)\n    * You can also install the requirements by running this in the R CLI (by typing `R` in a terminal window):\n\n```\n    install.packages('rgdal')\n    install.packages('alphahull')\n    install.packages('igraph')\n    install.packages('shapefiles')\n```\n\n* Test that everything in R is installed, on the CLI you should be able to run this with no errors:\n\n```\n    library(rgdal)\n    library(alphahull)\n    library(igraph)\n    library(shapefiles)\n    quit() #: this will quit R\n```\n\n* [GIMP]\n* [GDAL Tools], on OS X try [version 1.9](http://www.kyngchaos.com/files/software/frameworks/GDAL_Complete-1.9.dmg). Per [MapBox](https://www.mapbox.com/tilemill/docs/guides/gdal/): The first time you install the GDAL package there is one additional step to make sure you can access these programs. In Mac OS, Open the Terminal application and run the following commands:\n\n```\n    echo 'export PATH=/Library/Frameworks/GDAL.framework/Programs:$PATH' >> ~/.bash_profile\n    source ~/.bash_profile\n```\n\n* It is also a good idea to install [QGIS] to test your results\n\n"}
{"id": 17, "title": "mplleaflet-README.md", "text": "* [jinja2](http://jinja.pocoo.org/)\n\nOptional\n* [pyproj](https://code.google.com/p/pyproj/) Only needed if you only use non-WGS-84 projections.\n* [GeoPandas](https://github.com/kjordahl/geopandas) To make your life easier.\n"}
{"id": 18, "title": "pose-residual-network-pytorch-README.md", "text": "```\npython\npytorch\nnumpy\ntqdm\npycocotools\nprogress\nscikit-image\n```\n\n"}
{"id": 19, "title": "DBNet-README.md", "text": "* **Tensorflow 1.2.0**\n* Python 2.7\n* CUDA 8.0+ (For GPU)\n* Python Libraries: numpy, scipy and __laspy__\n\nThe code has been tested with Python 2.7, Tensorflow 1.2.0, CUDA 8.0 and cuDNN 5.1 on Ubuntu 14.04. But it may work on more machines (directly or through mini-modification), pull-requests or test report are well welcomed.\n\n"}
{"id": 20, "title": "DID-MDN-README.md", "text": "1. Linux\n2. Python 2 or 3\n3. CPU or NVIDIA GPU + CUDA CuDNN (CUDA 8.0)\n \n"}
{"id": 21, "title": "readgssi-README.md", "text": "Strongly recommended to install via [anaconda](https://www.anaconda.com/download):\n- [`obspy`](https://obspy.org/)\n- [`matplotlib`](https://matplotlib.org/)\n- [`numpy`](http://www.numpy.org/)\n- [`pandas`](https://pandas.pydata.org/)\n- [`h5py`](https://www.h5py.org/)\n\nInstall via `pip`:\n- [`pynmea2`](https://pypi.org/project/pynmea2/)\n- [`geopy`](https://pypi.org/project/geopy/)\n- [`pytz`](https://pypi.org/project/pytz/)\n\n"}
{"id": 22, "title": "RESCAN-README.md", "text": "- Python>=3.6\n- Pytorch>=4.1.0\n- Opencv>=3.1.0\n- tensorboardX\n\n"}
{"id": 23, "title": "facebookresearch-pyrobot-README.md", "text": "* Install **Ubuntu 16.04**\n\n* Download the installation script\n```bash\nsudo apt update\nsudo apt-get install curl\ncurl 'https://raw.githubusercontent.com/facebookresearch/pyrobot/master/robots/LoCoBot/install/locobot_install_all.sh' > locobot_install_all.sh\n```\n\n* Run the script to install everything (ROS, realsense driver, etc.). **Please connect the nuc machine to a realsense camera before running the following commands**.\n```bash\nchmod +x locobot_install_all.sh \n./locobot_install_all.sh\n```\n\n"}
{"id": 24, "title": "DaSiamRPN-README.md", "text": "CPU: Intel(R) Core(TM) i7-7700 CPU @ 3.60GHz\nGPU: NVIDIA GTX1060\n\n- python2.7\n- pytorch == 0.3.1\n- numpy\n- opencv\n\n\n"}
{"id": 25, "title": "DaSiamRPN-README.md", "text": "- install pytorch, numpy, opencv following the instructions in the `run_install.sh`. Please do **not** use conda to install.\n- you can alternatively modify `/PATH/TO/CODE/FOLDER/` in `tracker_SiamRPN.m` \n  If the tracker is ready, you will see the tracking results. (EAO: 0.3827)\n\n\n"}
{"id": 26, "title": "hmr-README.md", "text": "- Python 2.7\n- [TensorFlow](https://www.tensorflow.org/) tested on version 1.3, demo alone runs with TF 1.12\n\n"}
{"id": 27, "title": "iter-reason-README.md", "text": "1. Tensorflow, tested with version 1.6 with Ubuntu 16.04, installed with:\n  ```Shell\n  pip install --ignore-installed --upgrade https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.6.0-cp27-none-linux_x86_64.whl\n  ```\n\n2. Other packages needed can be installed with `pip`:\n  ```Shell\n  pip install Cython easydict matplotlib opencv-python Pillow pyyaml scipy\n  ```\n\n3. For running COCO, the API can be installed globally:\n  ```Shell\n  #: any path is okay\n  mkdir ~/install && cd ~/install\n  git clone https://github.com/cocodataset/cocoapi.git cocoapi\n  cd cocoapi/PythonAPI\n  python setup.py install --user\n  ```\n\n"}
{"id": 28, "title": "GANimation-README.md", "text": "- Install PyTorch (version 0.3.1), Torch Vision and dependencies from http://pytorch.org\n- Install requirements.txt (```pip install -r requirements.txt```)\n\n"}
{"id": 29, "title": "3D-ResNets-PyTorch-README.md", "text": "* [PyTorch](http://pytorch.org/)\n\n```bash\nconda install pytorch torchvision cuda80 -c soumith\n```\n\n* FFmpeg, FFprobe\n\n```bash\nwget http://johnvansickle.com/ffmpeg/releases/ffmpeg-release-64bit-static.tar.xz\ntar xvf ffmpeg-release-64bit-static.tar.xz\ncd ./ffmpeg-3.3.3-64bit-static/; sudo cp ffmpeg ffprobe /usr/local/bin;\n```\n\n* Python 3\n\n"}
{"id": 30, "title": "SRN-Deblur-README.md", "text": "- Python2.7\n- Scipy\n- Scikit-image\n- numpy\n- Tensorflow 1.4 with NVIDIA GPU or CPU (cpu testing is very slow)\n\n"}
{"id": 31, "title": "hyvr-README.md", "text": "Python\n^^^^^^\nHyVR was developed for use with Python 3.4 or greater. It may be possible to use\nwith earlier versions of Python 3, however this has not been tested.\n\nDependencies\n^^^^^^^^^^^^^^\n\n* `numpy `_ <= 1.13.3\n* `matplotlib `_ <= 2.1.0\n* `scipy `_ = 1.0.0\n* `pandas `_ = 0.21.0\n* `flopy `_ == 3.2.9 (optional for modflow output)\n* `pyevtk `_ = 1.1.0 (optional for VTK output)\n* `h5py `_ (optional for HDF5 output)\n\n\n"}
